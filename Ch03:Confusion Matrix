from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
from sklearn import datasets, metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay
import seaborn as sns

# sklearn에서 제공해주는 datasets에서 digits 데이터셋 로딩
digits = datasets.load_digits()
n_samples = len(digits.images)
data = digits.images.reshape((n_samples, -1))

knn = KNeighborsClassifier(n_neighbors=6)

# 80:20으로 훈련데이터와 테스트데이터 구분
X_train, X_test, y_train, y_test = train_test_split(
    data, digits.target, test_size=0.2)

knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

# 정답과 추정값을 이용한 confusion matrix 작성
cm = confusion_matrix(y_test, y_pred)

# recall, precision, f1 score, accuracy 테이블
print(classification_report(y_test, y_pred))
print(cm)

# confusion matrix 표현
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=digits.target_names)
disp.plot()
plt.show()

# 해당 카테고리 전체에 대한 각 부분의 비율을 이용한 정규화된 confusion matrix
cm_normalized = confusion_matrix(y_test, y_pred, normalize='true')
print(cm_normalized)

# seaborn 라이브러리를 이용한 heatmap으로 confusion matrix 표현
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
